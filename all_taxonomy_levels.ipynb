{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import copy\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD, PCA\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to output and save table, graph, and topic breakdowns given LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topicBreakdown(df, lda):\n",
    "    vocab = df.columns\n",
    "    taxonomy = pd.read_csv('../hurwitzlab/data_sets/HMP_V13_taxonomy_fix.csv')\n",
    "    result = ''\n",
    "\n",
    "    for i, comp in enumerate(lda.components_):\n",
    "        vocab_comp = zip(vocab, comp)\n",
    "        sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "        result += (\"Topic \"+str(i)+\": \")\n",
    "        for t in sorted_words:\n",
    "            row = taxonomy[taxonomy['OTU_ID'] == t[0]]\n",
    "            if not row.empty:\n",
    "                result += (str(row.iat[0, 6]) + ' ')\n",
    "            else:\n",
    "                result += (\"Not Found\")\n",
    "        result += (\"\\n\")\n",
    "\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_sites = pd.read_csv('../hurwitzlab/data_sets/HMP_V13_participant_data.csv')\n",
    "\n",
    "body_site_mapping = {site: idx for idx, site in enumerate(body_sites['HMP_BODY_SITE'].unique())}\n",
    "\n",
    "body_site_ints = body_sites['HMP_BODY_SITE'].map(body_site_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../hurwitzlab/data_sets/HMP_V13_OTU_counts.csv\")\n",
    "df = df.drop(columns = ['PSN'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "\n",
    "# Initial dimensionality reduction\n",
    "pca = PCA(n_components=50)\n",
    "reduced_df = pca.fit_transform(scaled_df)\n",
    "\n",
    "# Dimensionality reduction for visualization\n",
    "tsne = TSNE(n_components=2, init='pca', random_state=0)\n",
    "result = tsne.fit_transform(reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_colors = ['red', 'blue', 'green', 'yellow', 'purple']#, 'orange', 'pink', 'brown', 'olive', 'cyan']\n",
    "cmap = ListedColormap(custom_colors)\n",
    "\n",
    "# Plot with body sites\n",
    "# Red = gut, blue = oral, green = airways, yellow = skin, purple = urogenital\n",
    "fig = plt.figure(1, figsize=(8, 8))\n",
    "plt.clf()\n",
    "scatter = plt.scatter(result[:, 0], result[:, 1], c=body_site_ints, cmap=cmap, s=15)\n",
    "plt.savefig(\"body_site_plot.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputTableandGraph(df, lda, tax_level, filter):\n",
    "    \n",
    "    frequency_table = df.values\n",
    "    topic_distributions = lda.transform(frequency_table)\n",
    "\n",
    "    strongest_topic_indices = topic_distributions.argmax(axis=1)\n",
    "\n",
    "    body_sites['Strongest_Topic'] = strongest_topic_indices\n",
    "\n",
    "    topic_counts_by_site = body_sites.groupby(['HMP_BODY_SITE', 'Strongest_Topic']).size().unstack(fill_value=0)\n",
    "\n",
    "    print(topic_counts_by_site)\n",
    "\n",
    "    LDA_mapping = {site: idx for idx, site in enumerate(body_sites['Strongest_Topic'].unique())}\n",
    "\n",
    "    LDA_ints = body_sites['Strongest_Topic'].map(LDA_mapping)\n",
    "\n",
    "    custom_colors = ['red', 'blue', 'green', 'yellow', 'purple', 'orange', 'pink', 'brown', 'olive', 'cyan']\n",
    "    cmap = ListedColormap(custom_colors)\n",
    "\n",
    "    fig = plt.figure(1, figsize=(8, 8))\n",
    "    plt.clf()\n",
    "    scatter = plt.scatter(result[:, 0], result[:, 1], c=LDA_ints, cmap=cmap, s=15)\n",
    "    plt.savefig(tax_level + \"_comp_plot_\" + str(filter) + \".svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to find optimal component number for each taxonomic level by perplexity, returning a graph and a table at that level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findComponentNum(tax_level, file_name, filter):\n",
    "    df = pd.read_csv('../hurwitzlab/data_sets/' + file_name + '.csv')\n",
    "    df = df.drop(columns = ['PSN'])\n",
    "\n",
    "    threshold = 10\n",
    "    #df[df < threshold] = 0\n",
    "\n",
    "    if (filter == 1):\n",
    "      df = df.loc[:, (df != 0).sum(axis=0) > threshold]\n",
    "    \n",
    "\n",
    "    #remove taxa that occur less than a certain number of times across all samples (prevalence)\n",
    "    #try things on mouth\n",
    "    #try scikit clustering methods (hierarchical and k-means clustering)\n",
    "\n",
    "    frequency_table = df.values\n",
    "\n",
    "    bestLDA = LatentDirichletAllocation(n_components=5, random_state=0)\n",
    "    bestLDA.fit(frequency_table)\n",
    "    lowestPerplexity = bestLDA.perplexity(frequency_table)\n",
    "    componentNum = 5\n",
    "    print(componentNum, ',', lowestPerplexity, '\\n')\n",
    "    componentNum += 1\n",
    "\n",
    "\n",
    "    decreasing = 1\n",
    "\n",
    "    while decreasing == 1 and componentNum <= 10:\n",
    "      LDA = LatentDirichletAllocation(n_components=componentNum, random_state=0)\n",
    "      LDA.fit(frequency_table)\n",
    "      perplexity = LDA.perplexity(frequency_table)\n",
    "\n",
    "      print(componentNum, ', ', perplexity, '\\n')\n",
    "      \n",
    "      if perplexity < lowestPerplexity:\n",
    "        bestLDA = copy.deepcopy(LDA)\n",
    "        lowestPerplexity = perplexity\n",
    "      else:\n",
    "        decreasing = 0\n",
    "\n",
    "      componentNum += 1\n",
    "\n",
    "    print(tax_level, '- Component number:', componentNum - 2 + decreasing, ', Perplexity:', lowestPerplexity, '\\n')\n",
    "\n",
    "    return bestLDA, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeAnalysis(tax_level, file_name, filter):\n",
    "    lda, df = findComponentNum(tax_level, file_name, filter)\n",
    "    #topicBreakdown(df, lda)\n",
    "    outputTableandGraph(df, lda, file_name, filter)\n",
    "    return df, lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phylum_df, Phylum_lda = completeAnalysis('Phylum', 'HMP_V13_Phylum_counts', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phylum_df, Phylum_lda = completeAnalysis('Phylum', 'HMP_V13_Phylum_counts', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTU_df, OTU_lda = completeAnalysis('OTU', 'HMP_V13_OTU_counts', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTU_df, OTU_lda = completeAnalysis('OTU', 'HMP_V13_OTU_counts', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genus_df, genus_lda = completeAnalysis('genus', 'HMP_V13_genus_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_df, family_lda = completeAnalysis('family', 'HMP_V13_family_counts', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_df, family_lda = completeAnalysis('family', 'HMP_V13_family_counts', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order_df, order_lda = completeAnalysis('order', 'HMP_V13_order_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_df, class_lda = completeAnalysis('class', 'HMP_V13_class_counts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
